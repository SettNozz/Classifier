{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/settnozz/tz_zpoken/env/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import uuid\n",
    "from os.path import join\n",
    "from math import ceil, floor, pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 28\n",
    "\n",
    "\n",
    "def add_gaussian_noise(X_imgs):\n",
    "    gaussian_noise_imgs = []\n",
    "    row, col, _ = X_imgs[0].shape\n",
    "    # Gaussian distribution parameters\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    \n",
    "    for X_img in X_imgs:\n",
    "        gaussian = np.random.random((row, col, 1)).astype(np.float32)\n",
    "        gaussian = np.concatenate((gaussian, gaussian, gaussian), axis = 2)\n",
    "        gaussian_img = cv2.addWeighted(X_img, 0.75, 0.25 * gaussian, 0.25, 0)\n",
    "        gaussian_noise_imgs.append(gaussian_img)\n",
    "    gaussian_noise_imgs = np.array(gaussian_noise_imgs, dtype = np.float32)\n",
    "    return gaussian_noise_imgs\n",
    "\n",
    "def rotate_images(X_imgs, start_angle, end_angle, n_images):\n",
    "    X_rotate = []\n",
    "    iterate_at = (end_angle - start_angle) / (n_images - 1)\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (None, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    radian = tf.placeholder(tf.float32, shape = (len(X_imgs)))\n",
    "    tf_img = tf.contrib.image.rotate(X, radian)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "        for index in range(n_images):\n",
    "            degrees_angle = start_angle + index * iterate_at\n",
    "            radian_value = degrees_angle * pi / 180  # Convert to radian\n",
    "            radian_arr = [radian_value] * len(X_imgs)\n",
    "            rotated_imgs = sess.run(tf_img, feed_dict = {X: X_imgs, radian: radian_arr})\n",
    "            X_rotate.extend(rotated_imgs)\n",
    "\n",
    "    X_rotate = np.array(X_rotate, dtype = np.float32)\n",
    "    return X_rotate\n",
    "\n",
    "\n",
    "def get_translate_parameters(index):\n",
    "    if index == 0: # Translate left 20 percent\n",
    "        offset = np.array([0.0, 0.2], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.8 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = int(ceil(0.8 * IMAGE_SIZE))\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 1: # Translate right 20 percent\n",
    "        offset = np.array([0.0, -0.2], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.8 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = int(floor((1 - 0.8) * IMAGE_SIZE))\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 2: # Translate top 20 percent\n",
    "        offset = np.array([0.2, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.8 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = int(ceil(0.8 * IMAGE_SIZE)) \n",
    "    else: # Translate bottom 20 percent\n",
    "        offset = np.array([-0.2, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.8 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = int(floor((1 - 0.8) * IMAGE_SIZE))\n",
    "        h_end = IMAGE_SIZE \n",
    "        \n",
    "    return offset, size, w_start, w_end, h_start, h_end\n",
    "\n",
    "def translate_images(X_imgs):\n",
    "    offsets = np.zeros((len(X_imgs), 2), dtype = np.float32)\n",
    "    n_translations = 4\n",
    "    X_translated_arr = []\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(n_translations):\n",
    "            X_translated = np.zeros((len(X_imgs), IMAGE_SIZE, IMAGE_SIZE, 3), \n",
    "                dtype = np.float32)\n",
    "            X_translated.fill(1.0) # Filling background color\n",
    "            base_offset, size, w_start, w_end, h_start, h_end = get_translate_parameters(i)\n",
    "            offsets[:, :] = base_offset \n",
    "            glimpses = tf.image.extract_glimpse(X_imgs, size, offsets)\n",
    "            \n",
    "            glimpses = sess.run(glimpses)\n",
    "            X_translated[:, h_start: h_start + size[0], \\\n",
    "             w_start: w_start + size[1], :] = glimpses\n",
    "            X_translated_arr.extend(X_translated)\n",
    "    X_translated_arr = np.array(X_translated_arr, dtype = np.float32)\n",
    "    return X_translated_arr\n",
    "\n",
    "\n",
    "def tf_resize_images(X_img_file_paths):\n",
    "    X_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, (None, None, 3))\n",
    "    tf_img = tf.image.resize_images(X, (IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                    tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        # Each image is resized individually as different image may be of different size.\n",
    "        for index, file_path in enumerate(X_img_file_paths):\n",
    "            img = mpimg.imread(file_path)[:, :, :3] # Do not read alpha channel.\n",
    "            resized_img = sess.run(tf_img, feed_dict = {X: img})\n",
    "            X_data.append(resized_img)\n",
    "\n",
    "    X_data = np.array(X_data, dtype = np.float32) # Convert to numpy\n",
    "    return X_data\n",
    "\n",
    "\n",
    "def central_scale_images(X_imgs, scales):\n",
    "    # Various settings needed for Tensorflow operation\n",
    "    boxes = np.zeros((len(scales), 4), dtype = np.float32)\n",
    "    for index, scale in enumerate(scales):\n",
    "        x1 = y1 = 0.5 - 0.5 * scale # To scale centrally\n",
    "        x2 = y2 = 0.5 + 0.5 * scale\n",
    "        boxes[index] = np.array([y1, x1, y2, x2], dtype = np.float32)\n",
    "    box_ind = np.zeros((len(scales)), dtype = np.int32)\n",
    "    crop_size = np.array([IMAGE_SIZE, IMAGE_SIZE], dtype = np.int32)\n",
    "    \n",
    "    X_scale_data = []\n",
    "    tf.reset_default_graph()\n",
    "    X = tf.placeholder(tf.float32, shape = (1, IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    # Define Tensorflow operation for all scales but only one base image at a time\n",
    "    tf_img = tf.image.crop_and_resize(X, boxes, box_ind, crop_size)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        for img_data in X_imgs:\n",
    "            batch_img = np.expand_dims(img_data, axis = 0)\n",
    "            scaled_imgs = sess.run(tf_img, feed_dict = {X: batch_img})\n",
    "            X_scale_data.extend(scaled_imgs)\n",
    "    \n",
    "    X_scale_data = np.array(X_scale_data, dtype = np.float32)\n",
    "    return X_scale_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_steps = 3000\n",
    "batch_size = 128\n",
    "\n",
    "num_input = 28\n",
    "num_classes = 9\n",
    "dropout = 0.25\n",
    "\n",
    "\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        # Convolution Layer with 32 filters and a kernel size of 5\n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
    "\n",
    "        # Convolution Layer with 64 filters and a kernel size of 3\n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "        # Max Pooling (down-sampling) with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "def model_fn(features, labels, mode):\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helpful functions for process data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(test_bool):\n",
    "    if test_bool:\n",
    "        dataset_folder = os.getcwd() + '/dataset/test/'  # '/home/settnozz/tz_zpoken/dataset/test/'\n",
    "    else:\n",
    "        dataset_folder = os.getcwd() + '/dataset/train/' # '/home/settnozz/tz_zpoken/dataset/train/'\n",
    "    labels = sorted(os.listdir(dataset_folder))  # ['I', 'II', 'III', 'IV', 'V', 'VI', 'VII', 'VIII']\n",
    "    list_of_classes_paths = [join(dataset_folder, i) for i in labels]\n",
    "    for i in list_of_classes_paths:\n",
    "        save_images(i, central_scale_images(generate_list_images_array(i), [0.90, 0.80, 0.75]))\n",
    "        save_images(i, translate_images(generate_list_images_array(i)))\n",
    "        save_images(i, rotate_images(generate_list_images_array(i), -15, 15, 10))\n",
    "        save_images(i, add_gaussian_noise(generate_list_images_array(i)))\n",
    "        print(f'Images for {i} class, is ready')\n",
    "\n",
    "def get_all_images_array(test_bool, nums, number_of_images):\n",
    "    data_image = []\n",
    "    if test_bool:\n",
    "        dataset_folder = os.getcwd() + '/dataset/test/'  # '/home/settnozz/tz_zpoken/dataset/test/'\n",
    "    else:\n",
    "        dataset_folder = os.getcwd() + '/dataset/train/' # '/home/settnozz/tz_zpoken/dataset/train/'\n",
    "    labels = sorted(os.listdir(dataset_folder))\n",
    "    list_of_classes_paths = [join(dataset_folder, i) for i in labels]\n",
    "    paths_to_classes = [join(dataset_folder, i) for i in labels]\n",
    "    x = [join(i, j) for i in paths_to_classes for j in os.listdir(i)]\n",
    "    for i in x:\n",
    "        image = cv2.imread(i, cv2.IMREAD_GRAYSCALE)\n",
    "        data_image.append((image - image.mean()) / (image.std() + 1e-8))\n",
    "    return np.array(data_image, dtype='float32'), np.array(sorted(nums * number_of_images), dtype='uint8')\n",
    "\n",
    "\n",
    "def generate_list_images_array(path_class):\n",
    "    file_list = sorted([path_class + '/' + i for i in os.listdir(path_class)])\n",
    "    return tf_resize_images(file_list)\n",
    "\n",
    "def save_images(path_to_class, arr_of_img):\n",
    "    for i in arr_of_img:\n",
    "        cv2.imwrite(path_to_class + '/' + str(uuid.uuid4()) + '.jpg', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation for all training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images for /home/settnozz/tz_zpoken/dataset/train/I class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/II class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/III class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/IV class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/V class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/VI class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/VII class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/train/VIII class, is ready\n"
     ]
    }
   ],
   "source": [
    "preprocessing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_all_images_array(False, [1,2,3,4,5,6,7,8], 1760)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpvgki49fy\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpvgki49fy', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f70d8a66c18>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "model = tf.estimator.Estimator(model_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmpvgki49fy/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.2789931, step = 1\n",
      "INFO:tensorflow:global_step/sec: 9.56456\n",
      "INFO:tensorflow:loss = 2.3426502, step = 101 (10.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 9.6161\n",
      "INFO:tensorflow:loss = 0.53809285, step = 201 (10.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 8.77297\n",
      "INFO:tensorflow:loss = 2.3115249, step = 301 (11.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 3.09897\n",
      "INFO:tensorflow:loss = 1.2084901, step = 401 (32.270 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.7798\n",
      "INFO:tensorflow:loss = 0.45703697, step = 501 (20.921 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.6612\n",
      "INFO:tensorflow:loss = 0.17225441, step = 601 (21.454 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.34838\n",
      "INFO:tensorflow:loss = 0.3368443, step = 701 (18.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.69425\n",
      "INFO:tensorflow:loss = 0.7001292, step = 801 (21.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.25686\n",
      "INFO:tensorflow:loss = 0.33439445, step = 901 (19.021 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.66465\n",
      "INFO:tensorflow:loss = 0.39430377, step = 1001 (21.438 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.1081\n",
      "INFO:tensorflow:loss = 0.888638, step = 1101 (19.577 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.10731\n",
      "INFO:tensorflow:loss = 0.13140206, step = 1201 (19.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78416\n",
      "INFO:tensorflow:loss = 0.139838, step = 1301 (20.902 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78143\n",
      "INFO:tensorflow:loss = 0.20315617, step = 1401 (20.913 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.13354\n",
      "INFO:tensorflow:loss = 0.2806446, step = 1501 (19.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.52561\n",
      "INFO:tensorflow:loss = 0.14014277, step = 1601 (22.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.96452\n",
      "INFO:tensorflow:loss = 0.027013566, step = 1701 (20.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.69184\n",
      "INFO:tensorflow:loss = 0.09703356, step = 1801 (21.314 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.78253\n",
      "INFO:tensorflow:loss = 0.25670326, step = 1901 (20.910 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.20945\n",
      "INFO:tensorflow:loss = 0.049444523, step = 2001 (19.196 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.97309\n",
      "INFO:tensorflow:loss = 0.053414263, step = 2101 (20.108 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.0117\n",
      "INFO:tensorflow:loss = 0.120174125, step = 2201 (19.954 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.07787\n",
      "INFO:tensorflow:loss = 0.03842876, step = 2301 (19.692 sec)\n",
      "INFO:tensorflow:global_step/sec: 5.01749\n",
      "INFO:tensorflow:loss = 0.0064852387, step = 2401 (19.931 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.70324\n",
      "INFO:tensorflow:loss = 0.014368286, step = 2501 (21.261 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.69346\n",
      "INFO:tensorflow:loss = 0.07072153, step = 2601 (21.307 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.79535\n",
      "INFO:tensorflow:loss = 0.008724106, step = 2701 (20.855 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.83975\n",
      "INFO:tensorflow:loss = 0.0015126019, step = 2801 (20.660 sec)\n",
      "INFO:tensorflow:global_step/sec: 4.8102\n",
      "INFO:tensorflow:loss = 0.0031094574, step = 2901 (20.790 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmpvgki49fy/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.005136396.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f70c54fd8d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=X, y=np.array(Y),\n",
    "    batch_size=batch_size, num_epochs=None, shuffle=True)\n",
    "model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data augmentation for all testing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images for /home/settnozz/tz_zpoken/dataset/test/I class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/II class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/III class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/IV class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/V class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/VI class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/VII class, is ready\n",
      "Images for /home/settnozz/tz_zpoken/dataset/test/VIII class, is ready\n"
     ]
    }
   ],
   "source": [
    "preprocessing(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = get_all_images_array(True, [1,2,3,4,5,6,7,8], 440)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-05-21-18:55:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpvgki49fy/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-05-21-18:55:37\n",
      "INFO:tensorflow:Saving dict for global step 3000: accuracy = 1.0, global_step = 3000, loss = 0.0025802986\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'loss': 0.0025802986, 'global_step': 3000}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x=X, y=Y,\n",
    "    batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.evaluate(input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task has been done. Accuracy 99+%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
